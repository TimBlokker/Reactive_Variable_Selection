---
title: "Variable Selection"
output: html_notebook
runtime: shiny
editor_options: 
  markdown: 
    wrap: sentence
  fig_width: 10 
  fig_height: 10
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(leaps)
library(corrplot)
library(dplyr)
library(glmnet) #lasso
library(MASS) #MASS::select interferes with dplyr::select, so need to call all dplyr::select calls with dplyr::select to make clear that we want to use dplyr::select and not MASS::select
```

```{r}
#setwd("Variable_Selection")
getwd()
```

## Reading the matrices

```{r}
#Rabies
transition_distances_rabies_mp<-read.csv("input/transition_distances_batRABV.MCC.keep.target.heights.treesMP.csv",  
                                         row.names = 1)
transition_distances_rabies_ml<-read.csv("input/transition_distances_batRABV.MCC.keep.target.heights.treesML.csv",  
                                         row.names = 1)
transition_distances_rabies_tt<-read.csv("input/transition_distances_batRABV.MCC.keep.target.heights.treesTT.csv", 
                                         row.names=1)

#Ebola
transition_distances_ebola_mp<-read.csv("input/transition_distances_ebola_not_annotated.treeMP.csv",  
                                        row.names = 1)
transition_distances_ebola_ml<-read.csv("input/transition_distances_ebola_not_annotated.treeML.csv", 
                                        row.names = 1)
transition_distances_ebola_tt<-read.csv("input/transition_distances_ebola_not_annotated.treeTT.csv",
                                        row.names = 1)

#Test
transition_distances_pdvc_mp<-read.csv("input/transition_distances_PDCV_discrete_MCC.treeMP.csv",
                                       row.names = 1)
transition_distances_pdvc_ml<-read.csv("input/transition_distances_PDCV_discrete_MCC.treeML.csv",
                                       row.names = 1)
transition_distances_pdvc_tt<-read.csv("input/transition_distances_PDCV_discrete_MCC.treeTT.csv", 
                                       row.names = 1)

#Influenza
transition_distances_influenza_mp<-read.csv("input/transition_distances_h3_small_sample.MCC.treMP.csv", 
                                            row.names = 1)
transition_distances_influenza_ml<-read.csv("input/transition_distances_h3_small_sample.MCC.treML.csv", 
                                            row.names = 1)
transition_distances_influenza_tt<-read.csv("input/transition_distances_h3_small_sample.MCC.treTT.csv", 
                                           row.names = 1)

transition_distances_rabies_mp <- transition_distances_rabies_mp[colnames(transition_distances_rabies_mp)!="Key"]
transition_distances_rabies_ml <- transition_distances_rabies_ml[!colnames(transition_distances_rabies_ml) %in% c("Transition_Rates", "Key")]
transition_distances_rabies_tt <- transition_distances_rabies_tt[colnames(transition_distances_rabies_tt)!="Key"]
transition_distances_ebola_mp <- transition_distances_ebola_mp[colnames(transition_distances_ebola_mp)!="Key"]
transition_distances_ebola_ml <- transition_distances_ebola_ml[!colnames(transition_distances_ebola_ml) %in% c("Transition_Rates", "Key")]
transition_distances_ebola_tt <- transition_distances_ebola_tt[colnames(transition_distances_ebola_tt)!="Key"]
transition_distances_pdvc_mp <- transition_distances_pdvc_mp[colnames(transition_distances_pdvc_mp)!="Key"]
transition_distances_pdvc_ml <- transition_distances_pdvc_ml[!colnames(transition_distances_pdvc_ml) %in% c("Transition_Rates", "Key")]
transition_distances_pdvc_tt <- transition_distances_pdvc_tt[colnames(transition_distances_pdvc_tt)!="Key"]
transition_distances_influenza_mp <- transition_distances_influenza_mp[colnames(transition_distances_influenza_mp)!="Key"]
transition_distances_influenza_ml <- transition_distances_influenza_ml[!colnames(transition_distances_influenza_ml) %in% c("Transition_Rates", "Key")]
transition_distances_influenza_tt <- transition_distances_influenza_tt[colnames(transition_distances_influenza_tt)!="Key"]
```


```{r}
matrices_list_x <- list(
  "transition_distances_rabies_mp"= transition_distances_rabies_mp ,
   "transition_distances_rabies_ml" = transition_distances_rabies_ml ,
   "transition_distances_rabies_tt" = transition_distances_rabies_tt ,
   "transition_distances_ebola_mp" = transition_distances_ebola_mp ,
   "transition_distances_ebola_ml" = transition_distances_ebola_ml ,
   "transition_distances_ebola_tt" = transition_distances_ebola_tt ,
   "transition_distances_pdvc_mp" = transition_distances_pdvc_mp ,
   "transition_distances_pdvc_ml" = transition_distances_pdvc_ml ,
   "transition_distances_pdvc_tt" = transition_distances_pdvc_tt ,
   "transition_distances_influenza_mp" = transition_distances_influenza_mp ,
   "transition_distances_influenza_ml" = transition_distances_influenza_ml ,
   "transition_distances_influenza_tt" = transition_distances_influenza_tt 
)
```

```{r}
checkboxInput(
  inputId="standardize",
  label="Standardize predictors",
  value=FALSE
)
```


```{r}
#'Function to stadardize predictor variables
#'@param df dataframe to standardize
#'@return dataframe with standardized predictor variable
standardize_pred<-function(df, response="Transition" ){
     response_df<-save_response(df, response)
     df<-df%>%dplyr::select(!starts_with(response))
     df<-sweep(df,2, apply(df, 2, var), "/")
     df<-sweep(df,2, apply(df, 2, mean), "-")
     merge_response(response_df, df)
}

save_response<-function(df, response){
  df%>%dplyr::select(starts_with(response))
}

merge_response<-function(df1, df2){
  data.frame(df1, df2)
}

matrices_list<-reactive({
  if(!is.null(input$standardize)){
  if(input$standardize==TRUE){
    return(lapply(matrices_list_x, standardize_pred))
  }
  return(matrices_list_x)
  }
})

observeEvent(input$standardize,{
  matrices_list()
})

```

## Choose matrix to analyze

```{r}
output$input<-renderUI({
  selectInput("matrix",
              label = "Transition and Distances Matrix",
              choices =  names(matrices_list())
  )
})
uiOutput("input")
```


```{r}

output$response <-renderUI({
  req(input$matrix)
  selectInput("response",
            label = "Response variable",
            choices= colnames(matrices_list()[[input$matrix]] %>% dplyr::select(starts_with("Transition"))))
    })

uiOutput("response")
```

## Correlation Plot
 
```{r, fig.width = 20, fig.height = 20}
renderPlot({
  req(input$matrix)
  cor_matrix<-cor(matrices_list()[[input$matrix]])
  corrplot::corrplot(cor_matrix, type="upper", order="hclust", title = input$matrix, tl.cex = 1.5)
},
width = 800, 
height = 800)
```

## Define reactives to build the regression calls with

```{r}
predictors<-reactive({
  req(input$matrix)
  matrices_list()[[input$matrix]]%>%
    dplyr::select(!starts_with("Transition"))
})

f<-reactive({
  req(input$matrix, input$response)
  as.formula(paste0(input$response, "~",
                       paste(colnames(predictors()),
                             collapse = "+")))
})

data<-reactive({
  req(input$response, input$matrix)
  matrices_list()[[input$matrix]]%>%
     dplyr::select(c(!starts_with("Transition"),matches(input$response)))
})
```


```{r}
culDifClust<-reactive({
  req(input$response, input$matrix)
  d<-dist(1-abs(cor(predictors())))
  hclust(d, method="average")  #AVARAGE LINK
})

renderPlot({
# Rectangle dendrogram using ggplot2
dend<-as.dendrogram(culDifClust())
ggdendro::ggdendrogram(dend) 
})
```


```{r}
 numericInput(
    inputId= "num_clusters",
    label="Number of clusters:",
    value=3,
    min=1)

culDif.gp <- reactive({
  cutree(culDifClust(),k=input$num_clusters)
})

clusterd<-reactive({
  data.frame("Cluster_num"=culDif.gp(), abs(cor(predictors())), "Predictors"=names(culDif.gp()))
})

 renderTable({
   clusterd()%>% 
     group_by(Cluster_num) %>%
     summarise(Predictors=paste0(Predictors, collapse=", "))
 })

```



## Ordinary Least Squares Regression

```{r}
lm_ols<-reactive({
  req(input$response, input$matrix)
  lm <- lm( formula=f(), data=data())
  lm[["call"]][["formula"]]<-eval(lm[["call"]][["formula"]])
  lm[["call"]][["data"]]<-eval(input$matrix)
  lm
})

renderPrint({

  summary.lm(lm_ols())
})

```

## Leaps package : Best model for every amount of predictors, forward and backward selection

### Select the method

```{r}
selectInput("step_method",
            label = "Stepwise selection method:",
            choices =  c("exhaustive", "backward", "forward"))
```

The variable to be included is marked with an asterix:

```{r}
lm_regsubsets<-reactive({
  req(input$response, input$matrix)
  lm_regsubsets <- leaps::regsubsets(
     x=f(),
     data=data(),
     nvmax = length(colnames(data())),
     method=input$step_method)
    
  lm_regsubsets[["call"]][[2]]<-f()
  #lm_regsubsets[["call"]][[3]]<-eval(data()) 
  lm_regsubsets
})

sum_regsubsets<-reactive({
  req(lm_regsubsets())
  summary(lm_regsubsets())
})
selectInput(
  inputId="crit.plot",
  label="Selection criterium:",
  choices=c("bic", "Cp", "r2", "adjr2"),
  selected="bic"
)
renderPlot({
  req(input$crit.plot)
  plot(lm_regsubsets(),scale=input$crit.plot)
  })
```


### Select the criterium

```{r}
selectInput("selection_crit",
            label = "Selection criterium:",
            choices = c("rsq", "rss", "adjr2", "cp", "bic"))
```

```{r}
renderPlot({
  plot(get(input$selection_crit, sum_regsubsets()), xlab="Number of variables", ylab=input$selection_crit)
})
```

### What is the best number of selected variables (also check plots): Out of the box criteria

```{r}
renderPrint({
  req(input$selection_crit, sum_regsubsets())
  if(input$selection_crit %in% c("cp", "bic", "rss")){
    which(sum_regsubsets()[[input$selection_crit]]==min(sum_regsubsets()[[input$selection_crit]])) 
  }else{
    which(sum_regsubsets()[[input$selection_crit]]==max(sum_regsubsets()[[input$selection_crit]])) 
  }
})

```

BIC is more stringent then the other, also you see how RSS and RÂ² are not valid selection criteriums since they strictly improve with additionaly predictors.

## Cross-validation as "criterium"

#### Define a few functions to keep it readable

```{r}
#' Predict the response variable values for a given model including a given number of predictors and given new (test) data.
#'
#' @param regsubset_obj object of class regsubset that contains the models of different sizes
#' @param number_of_vars the size of the model to use for the predictions
#' @param newdata test data to carry out the predictions on
#' @return The matrix product of the model.matrix containing the selected variables (n x p) and the coefficient vector (p x 1) resulting in a n x 1 vector with the values of the response variable for every 
#' state transition
#' @credit Credit to the authors of the ILSR book
predict.regsubsets<-function(regsubset_obj,number_of_vars, newdata, f){
  mat<-model.matrix(f, newdata)
  coefi<-coef(regsubset_obj, number_of_vars)
  xvars<-names(coefi) #get the variable names included in the model
  mat[, xvars] %*% coefi #matrix multiplication resulting in a nx1 matrix/vector
}

#' Function to calculate the mean squared error given the actual and predicted values
#'
#' @param actual The actual values
#' @param predicted The predicted values
MSE<-function(actual, predicted){
  mean((((actual-predicted)[,1])^2))
}

```

```{r}
numericInput(
    inputId= "folds",
    label="Number of folds to include",
    value=10,
    min=2)
```


```{r}
mean_cv_errors<-reactive({
  req(input$response, input$step_method, input$matrix)
  
  k=input$folds #10 folds
  set.seed(1) #random seed
  
  folds=sample(1:k, nrow(data()), replace=T) #assigning numbers from 1:10 to each row in the dataframe : these are the folds
  cv_errors<-matrix(NA, k, dim(predictors())[2], dimnames = list(1:k, 1:dim(predictors())[2]))
  
  for(validation_fold in 1:k) {
    best.fit<-leaps::regsubsets(
      x=f(),
      data=data()%>%dplyr::filter(folds!=validation_fold),
      nvmax = dim(data())[2],
      method=input$step_method)
    
    for(number_of_vars in 1:dim(predictors())[2]){
      pred<-predict.regsubsets(best.fit, number_of_vars, data()%>%dplyr::filter(folds==validation_fold),f())
      cv_errors[validation_fold, number_of_vars ] <-MSE(data()%>%dplyr::select(input$response)%>%dplyr::filter(folds==validation_fold), pred)
    }
  }
  apply(cv_errors, 2, mean) #column-wise mean, which is the mean across the folds for each size of the model
})
```

```{r}
renderPlot(
  plot(mean_cv_errors())
)
```

### What is the best number of selected variables (also check plots): CV
```{r}
renderPrint({
  req(mean_cv_errors())
  which(mean_cv_errors()==min(mean_cv_errors()))
})
```

## The best model
```{r}
output$coefs<-renderUI({
  req(input$selection_crit, sum_regsubsets())
  numericInput(
    inputId= "number_of_vars",
    label="Get coefficients for selected number of var:",
    value=which(sum_regsubsets()[[input$selection_crit]]==max(sum_regsubsets()[[input$selection_crit]])), 
    min=1)
})
uiOutput("coefs")
```

```{r}
renderPrint({
  req(input$number_of_vars)
  coef(lm_regsubsets(), input$number_of_vars)
})
```


```{r}
lm_best<-reactive({
  req(input$number_of_vars, input$response, input$matrix)
  predictors<-names(coef(lm_regsubsets(), input$number_of_vars))[2:(input$number_of_vars+1)]
  f<-as.formula(paste0(input$response, "~",
                            paste(predictors, collapse = "+")))
  lm_best<-lm(f, data=data())
  lm_best[["call"]][["formula"]]<-eval(lm_best[["call"]][["formula"]])
  lm_best[["call"]][["data"]]<-eval(input$matrix)
  lm_best
})

renderPrint(
  summary.lm(lm_best())
)


```

## Automatic stepwise selection approaches
**AIC**

This methods do not only go backwards or only forward but go stepwise back and forth (also called sequential replacement), which is meant to reduce the risk to get stuck in local optima.In the output each line corresponds to the AIC that would be achieved when excluding ("-") or including ("+") the predictor of that line. Every "step" the action (+ or -) is carried out that results in the lowest AIC. 

For the rabies data set for the MP reconstruction we get a 3 variable model but we see that excluding "rangeOverlap" really only increases the AIC by 0.1 and so choosing the more parsimonous model with only "bodySize" and "hostDistances" is a an equally good model.
For ML the 2-variable model is selected both by the treeTime method as the ML reconstruction implemented in the R package.For the Transition rates as response variable "hostDistances" is still included in the model but instead of "bodysize" the "rangeOverlap" predictor is included in the model. Standardization of the predictor variable does not change inclusion of predictors in the model but impacts the size of the coefficients.

For the influenza dataset for every choice of the parameters the full model is selected, containing of "subsetDeff", subsetDgeo", "Dest_Pop_Size" and "Ori_Pop_Size".

For the ebola dataset, the AIC criterium selects a large amount of predictors for transition rates as  reponse 16 and for transition as response 9. And across the reconstruction methods the variables selected for transition counts varies between ML and MP with "originPrec", "originTmpss" and "originPopSize" being additinally included for the ML methods.


```{r}
 output$k<-renderUI({
 selectInput(
    inputId="k_crit",
    label="Input criterion",
    choices=c("AIC (k=2)"=2, "BIC (k=log(n))"=log(nrow(data())))
  )
})
uiOutput("k")
```


```{r}
renderPrint({
  req(input$k_crit)
  MASS::stepAIC(
    object = lm(f(), data=data()),
    direction = "both",
    trace=3,
    k=as.numeric(input$k_crit))
})
```


### Lasso selection

```{r}
cv_out<-reactive({
  req(input$response, f(), data())
  x <- model.matrix(object = f(), data = data())[,-1]
  y <- data()[[input$response]]
  grid<-10^seq(10,-2, length=100) #100 values of lambda covering the range 0.01 to 10^10

  set.seed(1)
  cv_out<-glmnet::cv.glmnet(x, y, alpha=1, lambda=grid, type.measure = "mse", nfolds = 10) #deviance a.k.a MSE
  cv_out
})

renderPlot({
  plot(cv_out())
})

renderTable({
  req(input$response, f(), data())
    x <- model.matrix(object = f(), data = data())[,-1]
    y <- data()[[input$response]]
    bestlam<-cv_out()$lambda.min
    grid<-10^seq(10,-2, length=100) #100 values of lambda covering the range 0.01 to 10^10
    out<-glmnet::glmnet(x,y,alpha=1, lambda=grid)
    lasso.coef<-predict(out, s=bestlam, type="coefficients")
    coefs<-lasso.coef[lasso.coef@i+1]
    names_coefs<-lasso.coef@Dimnames[[1]][lasso.coef@i+1]
    data.frame("Predictor"=names_coefs, "Coefficients"=coefs)
})

# library(plotmo)
# plot_glmnet(out, xvar="lambda", xlim=c(-3,1), ylim=c(-2,2), col=1:25, label=T)
# abline(v=log(bestlam), lty=2)
```

<!-- Best tuning parameter we can select based on the mean squared error/deviance as we also see in the plot above: -->

<!-- ```{r} -->
<!-- bestlam<-cv.out$lambda.min -->
<!-- bestlam -->
<!-- ``` -->

<!-- Assessing how good the model is by predicting the number of transitions for the non-used test observations and then calculating the MSE with the real transitions. -->

<!-- ```{r} -->
<!-- lasso.pred<-predict(cv.out, s=bestlam, newx=x[test,]) -->
<!-- mean((lasso.pred-y[test])^2) -->
<!-- ``` -->

<!-- ```{r} -->

<!-- set.seed(1) -->
<!-- out<-glmnet(x,y,alpha=1, lambda=0) -->
<!-- lasso.coef<-predict(out, s=bestlam, type="coefficients")#[1:25] -->
<!-- lasso.coef -->

<!-- ``` -->

<!-- ```{r} -->
<!-- pred<-predict(out,s=0, newx=x) -->
<!-- cor.test(pred,y) -->

<!-- ``` -->

<!-- ```{r} -->

<!-- grid<-10^seq(10,-2, length=100) #100 values of lambda covering the range 0.01 to 10^10 -->
<!-- x<-predictors() #this means everything except column 1, the intercept -->
<!-- y<-input$response -->
<!-- set.seed(1) -->
<!-- train<-sample(1:nrow(x), nrow(x)/2) -->
<!-- test<-(-train) -->
<!-- y.test<-y[test] -->

<!-- ``` -->

<!-- ```{r} -->
<!-- library(dplyr) -->
<!-- f<-as.formula(paste0("Transitions", "~", paste(colnames(matrices_list_x[["transition_distances_ebola_tt"]]%>%dplyr::select(!starts_with("Trans"))), collapse = "+"))) -->

<!-- data=matrices_list_x[["transition_distances_ebola_tt"]] -->


<!-- steps<-MASS::stepAIC( -->
<!--     object = lm(f, data=data), -->
<!--     direction = "both", -->
<!--     trace=FALSE, -->
<!--     k=2) -->
<!-- ``` -->

<!-- ```{r} -->

<!-- library(dplyr) -->
<!--  lm_regsubsets2 <- leaps::regsubsets( -->
<!--       x=as.formula(paste0("Transitions", "~", -->
<!--                         paste(colnames(matrices_list_x[["transition_distances_influenza_tt"]]%>%dplyr::select(!starts_with("Trans"))), collapse = "+"))), -->
<!--      data=matrices_list_x[["transition_distances_influenza_tt"]], -->
<!--      nvmax = min(10, length(colnames(matrices_list_x[["transition_distances_influenza_tt"]]))), -->
<!--       method="forward") -->
<!--  sum_regsubsets2<-summary(lm_regsubsets2) -->
<!--  sum_regsubsets2 -->
<!--  names(sum_regsubsets2) -->
<!-- paste0(names(coef(lm_regsubsets2, 4))[2:5], collapse="+") -->

<!-- ``` -->


## Subdivide in train and test to compare different approaches, different response, different variable selection techniques
<!-- The training data can be used to train the model and subsequently we can assess the goodness of the model via the test data. -->
<!-- ```{r} -->
<!-- set.seed(1) #set a random seed for reproducability -->
<!-- train_ind<-sample(dim(transition_distances_ebola_tt)[1], size=dim(transition_distances_ebola_tt)[1]/2, replace=F) #set half of the data randomly as training data -->
<!-- train<-transition_distances_ebola_tt[ train_ind,] #subset the actual data -->
<!-- test <-transition_distances_ebola_tt[-train_ind,] #do the same for the other half -->
<!-- ``` -->



<!-- ```{r} -->

<!-- names(data) -->

<!-- ``` -->

<!-- ```{r} -->

<!-- library(plotmo) -->

<!-- plot_glmnet(out, xvar="lambda", xlim=c(-3,1), ylim=c(-2,2), col=1:25, label=T) -->

<!-- abline(v=log(bestlam), lty=2) -->

<!-- ``` -->

<!-- The model has only 4 predictors left and consistently greatCircleDistances is among the selected predictors. -->
