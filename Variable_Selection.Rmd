---
title: "Variable Selection"
output: html_notebook
runtime: shiny
editor_options: 
  markdown: 
    wrap: sentence
  fig_width: 10 
  fig_height: 10
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(leaps)
library(corrplot)
library(dplyr)
library(glmnet) #lasso
library(MASS) #MASS::select interferes with dplyr::select, so need to call all dplyr::select calls with dplyr::select to make clear that we want to use dplyr::select and not MASS::select
```

```{r}
getwd()
```

## Reading the matrices

```{r}
#Rabies
transition_distances_rabies<-read.csv("input/transition_distances_batRABV.MCC.keep.target.heights.treesMPTRUE.csv", row.names = 1)
transition_distances_rabies_mp<-read.csv("input/transition_distances_batRABV.MCC.keep.target.heights.treesMPFALSE.csv", row.names = 1)
transition_distances_rabies_ml<-read.csv("input/transition_distances_batRABV.MCC.keep.target.heights.treesMLFALSE.csv", row.names = 1)
transition_distances_rabies_tt<-read.csv("input/transition_distances_batRABV.MCC.keep.target.heights.treesTTFALSE.csv", row.names=1)

#Ebola
transition_distances_ebola<-read.csv("input/transition_distances_Makona_1610_cds_ig.GLM.MCC.treeMPTRUE.csv", row.names = 1)
transition_distances_ebola_mp<-read.csv("input/transition_distances_ebola_not_annotated.treeMPFALSE.csv",row.names = 1)
transition_distances_ebola_ml<-read.csv("input/transition_distances_ebola_not_annotated.treeMLFALSE.csv",row.names = 1)
transition_distances_ebola_tt<-read.csv("input/transition_distances_ebola_not_annotated.treeTTFALSE.csv",row.names = 1)

#Influenza
transition_distances_influenza<-read.csv("input/transition_distances_h3_small_sample.MCC.treMPTRUE.csv", row.names = 1)
transition_distances_influenza_mp<-read.csv("input/transition_distances_h3_small_sample.MCC.treMPFALSE.csv", row.names = 1)
transition_distances_influenza_ml<-read.csv("input/transition_distances_h3_small_sample.MCC.treMLFALSE.csv",row.names = 1)
transition_distances_influenza_tt<-read.csv("input/transition_distances_h3_small_sample.MCC.treTTFALSE.csv", row.names = 1)
```

```{r}
#mistook rates as transition rates but below code chunk could still replace the for loop to find transition counts, much easier to read

# #Ebola
# ebola_tree<-treeio::read.beast("input/Makona_1610_cds_ig.GLM.MCC.tree")
# eb_tib<-as_tibble(ebola_tree)
# eb_tib<-eb_tib %>%
#   dplyr::mutate(parent_location_state=location.states[eb_tib$parent], rate=as.numeric(rate)) %>%
#   dplyr::select(rate, location.states, node, parent, parent_location_state)%>%
#   dplyr::filter(location.states!=parent_location_state)%>%
#   tidyr::unite("Key", parent_location_state,location.states, sep= "->", remove=FALSE ) %>%
#   dplyr::group_by(Key) %>%
#   dplyr::summarize(Transitions=n()) %>%
#   dplyr::arrange(desc(Transitions))
```

```{r}
transition_distances_rabies<- transition_distances_rabies_mp[colnames(transition_distances_rabies)!="Key"]
transition_distances_rabies_mp <- transition_distances_rabies[colnames(transition_distances_rabies_mp)!="Key"]
transition_distances_rabies_ml <- transition_distances_rabies_ml[!colnames(transition_distances_rabies_ml) %in% c("Transition_Rates", "Key")]
transition_distances_rabies_tt <- transition_distances_rabies_tt[colnames(transition_distances_rabies_tt)!="Key"]
transition_distances_ebola <- transition_distances_ebola_mp[colnames(transition_distances_ebola)!="Key"]
transition_distances_ebola_mp <- transition_distances_ebola[colnames(transition_distances_ebola_mp)!="Key"]
transition_distances_ebola_ml <- transition_distances_ebola_ml[!colnames(transition_distances_ebola_ml) %in% c("Transition_Rates", "Key")]
transition_distances_ebola_tt <- transition_distances_ebola_tt[colnames(transition_distances_ebola_tt)!="Key"]
transition_distances_influenza <- transition_distances_influenza[colnames(transition_distances_influenza)!="Key"]
transition_distances_influenza_mp <- transition_distances_influenza_mp[colnames(transition_distances_influenza_mp)!="Key"]
transition_distances_influenza_ml <- transition_distances_influenza_ml[!colnames(transition_distances_influenza_ml) %in% c("Transition_Rates", "Key")]
transition_distances_influenza_tt <- transition_distances_influenza_tt[colnames(transition_distances_influenza_tt)!="Key"]
```

```{r}
matrices_list_x <- list(
   "transition_distances_rabies"= transition_distances_rabies,
   "transition_distances_rabies_mp"= transition_distances_rabies_mp ,
   "transition_distances_rabies_ml" = transition_distances_rabies_ml ,
   "transition_distances_rabies_tt" = transition_distances_rabies_tt ,
   "transition_distances_ebola" = transition_distances_ebola ,
   "transition_distances_ebola_mp" = transition_distances_ebola_mp ,
   "transition_distances_ebola_ml" = transition_distances_ebola_ml ,
   "transition_distances_ebola_tt" = transition_distances_ebola_tt ,
   "transition_distances_influenza" = transition_distances_influenza,
   "transition_distances_influenza_mp" = transition_distances_influenza_mp ,
   "transition_distances_influenza_ml" = transition_distances_influenza_ml ,
   "transition_distances_influenza_tt" = transition_distances_influenza_tt 
)
```

```{r}
checkboxInput(
  inputId="standardize",
  label="Standardize predictors",
  value=FALSE
)
```

```{r}
#'Function to stadardize predictor variables
#'@param df dataframe to standardize
#'@return dataframe with standardized predictor variable
standardize_pred<-function(df){
  req(input$response)
     response_df<-data.frame(get(input$response, df))
     colnames(response_df)<-input$response
     binaries<-apply(df,2, function(variable) is.binary(variable))
     binaries_df<- data.frame(df[, binaries])
     colnames(binaries_df)<- names(binaries[which(binaries==TRUE)])
     df<-scale(df[, !colnames(df) %in% c(colnames(binaries_df), input$response)], center = T, scale = T)
     data.frame(response_df,binaries_df ,df)
}

renderTable({
  data.frame("Predictors"=colnames(predictors()),"var"=apply(predictors(),2,var), "mean"=  apply(predictors(),2,mean))
})

is.binary<-function(vector){
  if(length(unique(vector))==2) return(TRUE)
  return(FALSE)
}

matrices_list<-reactive({
  if(!is.null(input$standardize)){
  if(input$standardize==TRUE){
    return(lapply(matrices_list_x,  standardize_pred))
  }
  return(matrices_list_x)
  }
})

observeEvent(input$standardize,{
  matrices_list()
})

```

## Choose matrix to analyze

```{r}
output$input<-renderUI({
  selectInput("matrix",
              label = "Transition and Distances Matrix",
              choices =  names(matrices_list())
  )
})
uiOutput("input")
```

```{r}

output$response <-renderUI({
  req(input$matrix)
  selectInput("response",
            label = "Response variable",
            choices= colnames(matrices_list()[[input$matrix]] %>% dplyr::select(starts_with("Transition"))))
    })

uiOutput("response")
```

## Correlation Plot

```{r, fig.width = 20, fig.height = 20}
renderPlot({
  req(input$matrix)
  cor_matrix<-cor(matrices_list()[[input$matrix]])
  corrplot::corrplot(cor_matrix, type="upper", order="hclust", title = input$matrix, tl.cex = 1.5)
},
width = 800, 
height = 800)
```

```{r}
culDifClust<-reactive({
  req(input$response, input$matrix)
  d<-dist(1-abs(cor(predictors())))
  hclust(d, method="average")  #AVARAGE LINK
})

renderPlot({
# Rectangle dendrogram using ggplot2
dend<-as.dendrogram(culDifClust())
ggdendro::ggdendrogram(dend) 
})

```

## Cluster Variables by 1-abs(correlation)

```{r}
 numericInput(
    inputId= "num_clusters",
    label="Number of clusters:",
    value=3,
    min=1)

culDif.gp <- reactive({
  cutree(culDifClust(),k=input$num_clusters)
})

clusterd<-reactive({
  data.frame("Cluster_num"=culDif.gp(), abs(cor(predictors())), "Predictors"=names(culDif.gp()))
})

 renderTable({
   clusterd()%>% 
     group_by(Cluster_num) %>%
     summarise(Predictors=paste0(Predictors, collapse=", "))
 })

```

## Define reactives to build the regression calls with

```{r}
checkboxInput(
  inputId="interaction",
  label="Include interaction terms",
  value=FALSE
)
```

```{r}
predictors<-reactive({
  req(input$matrix)
  matrices_list()[[input$matrix]]%>%
    dplyr::select(!starts_with("Transition"))
})

f<-reactive({
  req(input$matrix, input$response, !is.null(input$interaction))
  if(input$interaction==TRUE){
  f<-as.formula(paste0(input$response, " ~ (",
                       paste(colnames(predictors()),
                             collapse = " + "), ")^2"))
 }else if(input$interaction==FALSE){
  f<-as.formula(paste0(input$response, " ~",
                       paste(colnames(predictors()),
                             collapse = " + ")))
  }
  f
})

data<-reactive({
  req(input$response, input$matrix)
  matrices_list()[[input$matrix]]%>%
     dplyr::select(c(!starts_with("Transition"),matches(input$response)))
})
```

## Ordinary Least Squares Regression

```{r}
lm_ols<-reactive({
  req(input$response, input$matrix)
  lm <- lm( formula=f(), data=data())
  lm[["call"]][["formula"]]<-eval(lm[["call"]][["formula"]])
  lm[["call"]][["data"]]<-eval(input$matrix)
  lm
})

renderPrint({

  summary.lm(lm_ols())
})

```

## Leaps package : Best model for every amount of predictors, forward and backward selection

### Select the method

```{r}
selectInput("step_method",
            label = "Stepwise selection method:",
            choices =  c("exhaustive", "backward", "forward"))
```

The variable to be included is marked with an asterix:

```{r}
lm_regsubsets<-reactive({
  req(input$response, input$matrix)
  lm_regsubsets <- leaps::regsubsets(
     x=f(),
     data=data(),
     nvmax = length(colnames(data())),
     method=input$step_method)
    
  lm_regsubsets[["call"]][[2]]<-f()
  #lm_regsubsets[["call"]][[3]]<-eval(data()) 
  lm_regsubsets
})

sum_regsubsets<-reactive({
  req(lm_regsubsets())
  summary(lm_regsubsets())
})
selectInput(
  inputId="crit.plot",
  label="Selection criterium:",
  choices=c("bic", "Cp", "r2", "adjr2"),
  selected="bic"
)
renderPlot({
  req(input$crit.plot)
  plot(lm_regsubsets(),scale=input$crit.plot)
  })
```

### Select the criterion

```{r}
selectInput("selection_crit",
            label = "Selection criterium:",
            choices = c("rsq", "rss", "adjr2", "cp", "bic"))
```

```{r}
renderPlot({
  plot(get(input$selection_crit, sum_regsubsets()), xlab="Number of variables", ylab=input$selection_crit)
})
```

### What is the best number of selected variables (also check plots): Out of the box criteria

```{r}
renderPrint({
  req(input$selection_crit, sum_regsubsets())
  if(input$selection_crit %in% c("cp", "bic", "rss")){
    which(sum_regsubsets()[[input$selection_crit]]==min(sum_regsubsets()[[input$selection_crit]])) 
  }else{
    which(sum_regsubsets()[[input$selection_crit]]==max(sum_regsubsets()[[input$selection_crit]])) 
  }
})

```

BIC is more stringent then the other, also you see how RSS and R² are not valid selection criteriums since they strictly improve with additionaly predictors.

## Cross-validation as "criterium"

#### Define a few functions to keep it readable

```{r}
#' Predict the response variable values for a given model including a given number of predictors and given new (test) data.
#'
#' @param regsubset_obj object of class regsubset that contains the models of different sizes
#' @param number_of_vars the size of the model to use for the predictions
#' @param newdata test data to carry out the predictions on
#' @return The matrix product of the model.matrix containing the selected variables (n x p) and the coefficient vector (p x 1) resulting in a n x 1 vector with the values of the response variable for every 
#' state transition
#' @credit Credit to the authors of the ILSR book
predict.regsubsets<-function(regsubset_obj,number_of_vars, newdata, f){
  mat<-model.matrix(f, newdata)
  coefi<-coef(regsubset_obj, number_of_vars)
  xvars<-names(coefi) #get the variable names included in the model
  mat[, xvars] %*% coefi #matrix multiplication resulting in a nx1 matrix/vector
}

#' Function to calculate the mean squared error given the actual and predicted values
#'
#' @param actual The actual values
#' @param predicted The predicted values
MSE<-function(actual, predicted){
  mean((((actual-predicted)[,1])^2))
}

```

```{r}
numericInput(
    inputId= "folds",
    label="Number of folds to include",
    value=10,
    min=2)
```

```{r}
mean_cv_errors<-reactive({
  req(input$response, input$step_method, input$matrix)
  
  k=input$folds #10 folds
  set.seed(1) #random seed
  
  folds=sample(1:k, nrow(data()), replace=T) #assigning numbers from 1:10 to each row in the dataframe : these are the folds
  cv_errors<-matrix(NA, k, dim(predictors())[2], dimnames = list(1:k, 1:dim(predictors())[2]))
  
  for(validation_fold in 1:k) {
    best.fit<-leaps::regsubsets(
      x=f(),
      data=data()%>%dplyr::filter(folds!=validation_fold),
      nvmax = dim(data())[2],
      method=input$step_method)
    
    for(number_of_vars in 1:dim(predictors())[2]){
      pred<-predict.regsubsets(best.fit, number_of_vars, data()%>%dplyr::filter(folds==validation_fold),f())
      cv_errors[validation_fold, number_of_vars ] <-MSE(data()%>%dplyr::select(input$response)%>%dplyr::filter(folds==validation_fold), pred)
    }
  }
  apply(cv_errors, 2, mean) #column-wise mean, which is the mean across the folds for each size of the model
})
```

```{r}
renderPlot(
  plot(mean_cv_errors())
)
```

### What is the best number of selected variables (also check plots): CV

```{r}
renderPrint({
  req(mean_cv_errors())
  which(mean_cv_errors()==min(mean_cv_errors()))
})
```

## The best model according to stepwise techniques

```{r}
output$coefs<-renderUI({
  req(input$selection_crit, sum_regsubsets())
  numericInput(
    inputId= "number_of_vars",
    label="Get coefficients for selected number of var:",
    value=which(sum_regsubsets()[[input$selection_crit]]==max(sum_regsubsets()[[input$selection_crit]])), 
    min=1)
})
uiOutput("coefs")
```

```{r}
renderPrint({
  req(input$number_of_vars)
  coef(lm_regsubsets(), input$number_of_vars)
})
```

```{r}
lm_best<-reactive({
  req(input$number_of_vars, input$response, input$matrix)
  predictors<-names(coef(lm_regsubsets(), input$number_of_vars))[2:(input$number_of_vars+1)]
  f<-as.formula(paste0(input$response, "~",
                            paste(predictors, collapse = "+")))
  lm_best<-lm(f, data=data())
  lm_best[["call"]][["formula"]]<-eval(lm_best[["call"]][["formula"]])
  lm_best[["call"]][["data"]]<-eval(input$matrix)
  lm_best
})

renderPrint(
  summary.lm(lm_best())
)


```

## Automatic stepwise selection approaches

**AIC**

This methods do not only go backwards or only forward but go stepwise back and forth (also called sequential replacement), which is meant to reduce the risk to get stuck in local optima.In the output each line corresponds to the AIC that would be achieved when excluding ("-") or including ("+") the predictor of that line.
Every "step" the action (+ or -) is carried out that results in the lowest AIC.

For the **rabies** data set for the MP reconstruction we get a 3 variable model but we see that excluding "rangeOverlap" really only increases the AIC by 0.1 and so choosing the more parsimonous model with only "bodySize" and "hostDistances" is a an equally good model.
For ML the 2-variable model is selected both by the treeTime method as the ML reconstruction implemented in the R package.For the Transition rates as response variable "hostDistances" is still included in the model but instead of "bodysize" the "rangeOverlap" predictor is included in the model.
Standardization of the predictor variable does not change inclusion of predictors in the model but impacts the size of the coefficients.
So for rabies the transition rate approach via treeTime is closer to the beast results as described in the tutorial.

For the influenza dataset for every choice of the parameters the full model is selected, containing of "subsetDeff", subsetDgeo", "Dest_Pop_Size" and "Ori_Pop_Size".

For the ebola dataset, the AIC criterium selects a large amount of predictors for transition rates as reponse 16 and for transition as response 9.
And across the reconstruction methods the variables selected for transition counts varies between ML and MP with "originPrec", "originTmpss" and "originPopSize" being additinally included for the ML methods.

```{r}
 output$k<-renderUI({
 selectInput(
    inputId="k_crit",
    label="Input criterion",
    choices=c("AIC (k=2)"=2, "BIC (k=log(n))"=log(nrow(data())))
  )
})
uiOutput("k")
```

```{r}
renderPrint({
  req(input$k_crit)
  MASS::stepAIC(
    object = lm(f(), data=data()),
    direction = "both",
    trace=3,
    k=as.numeric(input$k_crit))
})
```

### Lasso selection

```{r}
cv_out<-reactive({
  req(input$response, f(), data())
  x <- model.matrix(object = f(), data = data())[,-1]
  y <- data()[[input$response]]
  grid<-10^seq(10,-2, length=100) #100 values of lambda covering the range 0.01 to 10^10

  set.seed(1)
  cv_out<-glmnet::cv.glmnet(x, y, alpha=1, lambda=grid, type.measure = "mse", nfolds = 10 ) #deviance a.k.a MSE
  cv_out
})

renderPlot({
  plot(cv_out())
})

out<-reactive({
   req(input$response, f(), data(), cv_out())
    x <- model.matrix(object = f(), data = data())[,-1]
    y <- data()[[input$response]]
    grid<-10^seq(10,-2, length=100) #100 values of lambda covering the range 0.01 to 10^10
    out<-glmnet::glmnet(x,y,alpha=1, lambda=grid, standardize =T)
})

renderPrint({
  req(input$response, f(), data())
    #bestlam<-cv_out()$lambda.min
    coef(cv_out(), s="lambda.min")
    # lasso.coef<-predict(out(), s=bestlam, type="coefficients")
    # coefs<-lasso.coef[lasso.coef@i+1]
    # names_coefs<-lasso.coef@Dimnames[[1]][lasso.coef@i+1]
    # data.frame("Predictor"=names_coefs, "Coefficients"=coefs)
})

renderTable({
  req(input$response, f(), data())
    coefs<-coef(cv_out(), s="lambda.min") %>% as.matrix()
    names_coefs<-rownames(coefs)
    df<-data.frame("Predictor"=names_coefs, "Coefficients"=as.vector(coefs))
    df %>% filter(Coefficients!=0)
})

```

The plot below shows the crossvalidation error as a red-dotted line and the upper and lower standard deviation.

```{r}
renderPlot({
  req(cv_out(), out(), input$number_of_vars)
  bestlam<-cv_out()$lambda.min
  lasso.coef<-predict(out(), s=bestlam, type="coefficients")
  coefs<-lasso.coef[lasso.coef@i+1]
 plotmo::plot_glmnet(out(),xvar= "lambda", label=input$number_of_vars, ylim=c(min(coefs),max(coefs)))
 abline(v=log(cv_out()$lambda.min), lty=2)
})
```

## Elastic Net


```{r}
get_best_result <- function(caret_fit) {
  best<-which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
  best_result <- caret_fit$results[best, ]
  rownames(best_result) <- NULL
  best_result
}


elnet<-reactive({
  req(data(), f())
  set.seed(42)
  cv_10 = caret::trainControl(method = "cv", number =10)
  
  elnet <- caret::train(
    f(), data = data(),
    method = "glmnet",
    trControl = cv_10
  )
  elnet
})

renderPrint({
  req(elnet())
  get_best_result(elnet())
})

```

This output is not very satisfactory, it does not seem to be easy to get the selected variables and coefficients.
These methods purely aim at prediction with optimized tuning parameters alpha and lambda.

```{r}
# 
# # https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html
# 
get_best_result <- function(caret_fit) {
  best<-which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
  best_result <- caret_fit$results[best, ]
  rownames(best_result) <- NULL
  best_result
}
f<-as.formula(paste0("Transitions", "~", paste(colnames(matrices_list_x[["transition_distances_ebola_tt"]]%>%dplyr::select(!starts_with("Trans"))), collapse = "+")))
data=matrices_list_x[["transition_distances_ebola_tt"]]


set.seed(42)
cv_10 = caret::trainControl(method = "cv", number =10)
elnet <- caret::train(
f, data = data,
method = "glmnet",
trControl = cv_10)


get_best_result(elnet)

grid<-10^seq(5,-5, length=100) #100 values of lambda covering the range 0.01 to 10^10

foldid=sample(1:10,size=length(y),replace=TRUE)


alpha.seq=seq(0,1,0.1)

cv.alpha<-lapply(alpha.seq, function(alpha) glmnet::cv.glmnet(x,y,lambda=grid ,foldid=foldid,alpha=alpha))

par(mfrow=c(5,2))
lapply(cv.alpha, function(alpha) plot(alpha))
plot(cv1);
plot(cv.5);
plot(cv0)
plot(log(cv1$lambda),cv1$cvm,pch=19,col="red",xlab="log(Lambda)",ylab=cv1$name)
lapply(cv.alpha, function(alpha) points(log(alpha$lambda),alpha$cvm,pch=19,col="grey"))
points(log(cv0$lambda),cv0$cvm,pch=19,col="blue")
legend("topleft",legend=c("alpha= 1","alpha= .5","alpha 0"),pch=19,col=c("red","grey","blue"))

x <- model.matrix(object = f, data = data)[,-1]
y <- data[["Transitions"]]
out<-glmnet::glmnet(x,y,alpha=0.5, standardize =T)



```

<!-- ```{r} -->

<!-- library(dplyr) -->

<!-- f<-as.formula(paste0("Transitions", "~", paste(colnames(matrices_list_x[["transition_distances_ebola_tt"]]%>%dplyr::select(!starts_with("Trans"))), collapse = "+"))) -->

<!-- data=matrices_list_x[["transition_distances_ebola_tt"]] -->

<!-- steps<-MASS::stepAIC( -->

<!--     object = lm(f, data=data), -->

<!--     direction = "both", -->

<!--     trace=FALSE, -->

<!--     k=2) -->

<!-- ``` -->

<!-- ```{r} -->

<!-- library(dplyr) -->

<!--  lm_regsubsets2 <- leaps::regsubsets( -->

<!--       x=as.formula(paste0("Transitions", "~", -->

<!--                         paste(colnames(matrices_list_x[["transition_distances_influenza_tt"]]%>%dplyr::select(!starts_with("Trans"))), collapse = "+"))), -->

<!--      data=matrices_list_x[["transition_distances_influenza_tt"]], -->

<!--      nvmax = min(10, length(colnames(matrices_list_x[["transition_distances_influenza_tt"]]))), -->

<!--       method="forward") -->

<!--  sum_regsubsets2<-summary(lm_regsubsets2) -->

<!--  sum_regsubsets2 -->

<!--  names(sum_regsubsets2) -->

<!-- paste0(names(coef(lm_regsubsets2, 4))[2:5], collapse="+") -->

<!-- ``` -->

## Subdivide in train and test to compare different approaches, different response, different variable selection techniques
